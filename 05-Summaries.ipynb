{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate summaries for each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "from pyLDAvis import gensim as gensimvis\n",
    "import spacy\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pizza_sentences_sample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df = pd.read_pickle('business.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_index</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_id</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_val</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>I recently visited Pieology for the first time...</td>\n",
       "      <td>CsZu4mX7zrVw5kfM6Ca9wQ</td>\n",
       "      <td>[pieology, time, friend, selection, taste, pie]</td>\n",
       "      <td>4</td>\n",
       "      <td>variety/options</td>\n",
       "      <td>(1, Negative)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WWWufR135GEXKynwYjLdGg</td>\n",
       "      <td>Pieology Pizzeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  review_index  sentence_index  \\\n",
       "0     45           491               0   \n",
       "\n",
       "                                            sentence               review_id  \\\n",
       "0  I recently visited Pieology for the first time...  CsZu4mX7zrVw5kfM6Ca9wQ   \n",
       "\n",
       "                                           cleaned  topic       topic_name  \\\n",
       "0  [pieology, time, friend, selection, taste, pie]      4  variety/options   \n",
       "\n",
       "       sentiment  sentiment_val             business_id               name  \n",
       "0  (1, Negative)            1.0  WWWufR135GEXKynwYjLdGg  Pieology Pizzeria  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-topics within each main topic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groupby topic/subtopic with average sentiment value and frequency of topic/subtopic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WWWufR135GEXKynwYjLdGg'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Pieology Pizzeria\"\n",
    "business_id = df['business_id'][df['name']==name][0]\n",
    "stars = bus_df['stars'][bus_df['business_id'] == 'business_id']\n",
    "business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = pd.Series(bus_df['stars'][bus_df['business_id'] == business_id]).iloc[0]\n",
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>topic_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>zmfa8RNxqSuOJ9Nx-CMs_Q</td>\n",
       "      <td>0</td>\n",
       "      <td>pizza quality and style</td>\n",
       "      <td>1.942529</td>\n",
       "      <td>87</td>\n",
       "      <td>347</td>\n",
       "      <td>0.250720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>zmfa8RNxqSuOJ9Nx-CMs_Q</td>\n",
       "      <td>4</td>\n",
       "      <td>variety/options</td>\n",
       "      <td>2.156627</td>\n",
       "      <td>83</td>\n",
       "      <td>347</td>\n",
       "      <td>0.239193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>zmfa8RNxqSuOJ9Nx-CMs_Q</td>\n",
       "      <td>1</td>\n",
       "      <td>wait times</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>80</td>\n",
       "      <td>347</td>\n",
       "      <td>0.230548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>zmfa8RNxqSuOJ9Nx-CMs_Q</td>\n",
       "      <td>3</td>\n",
       "      <td>experience</td>\n",
       "      <td>1.786885</td>\n",
       "      <td>61</td>\n",
       "      <td>347</td>\n",
       "      <td>0.175793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>zmfa8RNxqSuOJ9Nx-CMs_Q</td>\n",
       "      <td>2</td>\n",
       "      <td>service</td>\n",
       "      <td>2.194444</td>\n",
       "      <td>36</td>\n",
       "      <td>347</td>\n",
       "      <td>0.103746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  topic               topic_name  avg_sentiment  \\\n",
       "1229  zmfa8RNxqSuOJ9Nx-CMs_Q      0  pizza quality and style       1.942529   \n",
       "1233  zmfa8RNxqSuOJ9Nx-CMs_Q      4          variety/options       2.156627   \n",
       "1230  zmfa8RNxqSuOJ9Nx-CMs_Q      1               wait times       2.075000   \n",
       "1232  zmfa8RNxqSuOJ9Nx-CMs_Q      3               experience       1.786885   \n",
       "1231  zmfa8RNxqSuOJ9Nx-CMs_Q      2                  service       2.194444   \n",
       "\n",
       "      topic_count  sentence_count  importance  \n",
       "1229           87             347    0.250720  \n",
       "1233           83             347    0.239193  \n",
       "1230           80             347    0.230548  \n",
       "1232           61             347    0.175793  \n",
       "1231           36             347    0.103746  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df.groupby(['business_id']).size().reset_index(name='counts')\n",
    "aggs = pd.merge (df, counts , how = 'left', on='business_id')\n",
    "\n",
    "\n",
    "aggs = aggs.groupby(['business_id','topic','topic_name']).agg({'sentiment_val':'mean', \n",
    "                                                'index':lambda x: x.nunique(),\n",
    "                                                'counts': 'mean'                                                \n",
    "                                               }).reset_index()\n",
    "aggs.columns = ['business_id','topic','topic_name','avg_sentiment', 'topic_count', 'sentence_count']\n",
    "aggs['importance'] = aggs['topic_count']/aggs['sentence_count']\n",
    "aggs = aggs.sort_values(by = ['business_id', 'importance'], ascending = False)\n",
    "aggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 1, 3, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(aggs['topic'][aggs['business_id'] == 'zmfa8RNxqSuOJ9Nx-CMs_Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic order of importance for each restaurant**  \n",
    "*For each restaurant, get list of topic/subtopics by order of frequency*  \n",
    "*Return infograph of average sentiment for each topic/subtopic*\n",
    "  \n",
    "**Representative sentence in each topic/subtopic**  \n",
    "*For each restaurant topic/subtopic item, get representative sentence*    \n",
    "*Append sentences to summary paragraph in order of importance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "def clean_sentences(sentences):\n",
    "    sentences = [re.sub(\"\\n|\\r\", \"\", s) for s in sentences]    \n",
    "    sentences = [s.lower() for s in sentences] # lower case    \n",
    "    sentences = [s.translate(str.maketrans('', '', string.punctuation)) for s in sentences] # remove punctuation\n",
    "    def lemmatize_alphanumeric(sentence):\n",
    "        words = [lemmatizer.lemmatize(word) for word in sentence.split() if word.isalpha()\n",
    "                and nlp.vocab[word].is_stop == False]\n",
    "        sentence = ' '.join(words)\n",
    "        return(sentence)    \n",
    "    sentences = [lemmatize_alphanumeric(s) for s in sentences] # lemmatize and remove non alpha-numeric characters\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.40824829 0.5        0.70710678] 0.6538387679126025\n",
      "[0.40824829 1.         0.         0.28867513] 0.424230856264669\n",
      "[0.5        0.         1.         0.35355339] 0.4633883476483183\n",
      "[0.70710678 0.28867513 0.35355339 1.        ] 0.5873338265936585\n"
     ]
    }
   ],
   "source": [
    "sentences = ['the crust is great', 'great authentic pizza', 'they have the best crust',\n",
    "             'the sauce is great and the crust is so doughy']\n",
    "mat = get_matrix(sentences)\n",
    "\n",
    "for i in mat:\n",
    "    print(i, i.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(sentences):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = set(stopwords.words(\"english\"))\n",
    "    cv = CountVectorizer(stop_words=stopwords)\n",
    "    \n",
    "    X_cv = cv.fit_transform(sentences)    \n",
    "    countvector = pd.DataFrame(X_cv.toarray(), columns=cv.get_feature_names())    \n",
    "    cosines = cosine_similarity(X_cv)\n",
    "    \n",
    "    return(cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sentences(cosines, n):\n",
    "    avg_cosines = []\n",
    "    for c in range(len(cosines)):\n",
    "        avg_cosines.append(cosines[c].mean())\n",
    "    \n",
    "    top_sentence_dict = {}\n",
    "    for i in sorted(range(len(avg_cosines)), key=lambda i: avg_cosines[i])[-n:]:\n",
    "        top_sentence_dict[i] = avg_cosines[i]\n",
    "    \n",
    "    top_sentence_i = []\n",
    "    for w in sorted(top_sentence_dict, key=top_sentence_dict.get, reverse=True):\n",
    "        top_sentence_i.append(w)\n",
    "    \n",
    "    return(top_sentence_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Staff are super friendly', 'Staff are super friendly as well!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_id = 'zmfa8RNxqSuOJ9Nx-CMs_Q'\n",
    "topic = 2\n",
    "n = 2\n",
    "\n",
    "sentences = list(df['sentence'][(df['business_id'] == business_id) & (df['topic'] == topic)])\n",
    "text = clean_sentences(sentences)\n",
    "cosines = get_matrix(text)\n",
    "\n",
    "top_sentence_i = get_top_sentences(cosines, n)\n",
    "\n",
    "rep_sentences = []\n",
    "for i in top_sentence_i:\n",
    "    rep_sentences.append(sentences[i].lstrip())\n",
    "    \n",
    "rep_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_sentences(business_id, topic, n):\n",
    "\n",
    "    sentences = list(df['sentence'][(df['business_id'] == business_id) & (df['topic'] == topic)])\n",
    "    \n",
    "    text = clean_sentences(sentences)\n",
    "    \n",
    "    cosines = get_matrix(text)\n",
    "    \n",
    "    top_sentence_i = get_top_sentences(cosines, n)\n",
    "    \n",
    "    rep_sentences = []\n",
    "    for i in top_sentence_i:\n",
    "        rep_sentences.append(sentences[i].lstrip())\n",
    "    \n",
    "    return(rep_sentences)\n",
    "\n",
    "\n",
    "def get_rep_sentences_tname(business_id, topic_name, n):\n",
    "    sentences = list(df['sentence'][(df['business_id'] == business_id) & (df['topic_name'] == topic_name)])    \n",
    "    text = clean_sentences(sentences)    \n",
    "    cosines = get_matrix(text)\n",
    "    top_sentence_i = get_top_sentences(cosines, n)    \n",
    "    rep_sentences = []\n",
    "    for i in top_sentence_i:\n",
    "        rep_sentences.append(sentences[i].lstrip())    \n",
    "    return(rep_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rep_sentences(business_id, topic, n):\n",
    "    rep_sentences = '. '.join(get_rep_sentences(business_id, topic, n))\n",
    "    return(rep_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Staff are super friendly',\n",
       " 'Staff are super friendly as well!',\n",
       " 'Very attentive staff',\n",
       " 'The attending staff was super attentive, and engaging, made sure our table always had food/condiments while we were waiting for the main course',\n",
       " 'The wait staff are wonderful here']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rep_sentences('zmfa8RNxqSuOJ9Nx-CMs_Q', 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Staff are super friendly. Staff are super friendly as well!. Very attentive staff. The attending staff was super attentive, and engaging, made sure our table always had food/condiments while we were waiting for the main course. The wait staff are wonderful here'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_rep_sentences('zmfa8RNxqSuOJ9Nx-CMs_Q', 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The bread and tomato sauce was a novel idea and the bruschetta was also novel- on crispy pizza dough with fresh tomatoes',\n",
       " '0/10: The bread and tomato sauce appetizer everyone raves about',\n",
       " 'Oh, and their bread and especially tomato dipping sauce were delicious',\n",
       " '50 for Bruschetta (tomatoes and bread - really?)',\n",
       " 'The pizza was horrible, hardly a toasted bread with tomato sauce and a few small pieces of cheese']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rep_sentences_tname('zmfa8RNxqSuOJ9Nx-CMs_Q', 'pizza quality and style', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggs(business_id, df):\n",
    "    \n",
    "    bus = df[df['business_id'] == business_id]\n",
    "    \n",
    "    sentence_count = bus.groupby(['business_id']).size().reset_index(name='counts')\n",
    "    \n",
    "    bus = pd.merge (bus, sentence_count , how = 'left', on='business_id')\n",
    "    aggs = bus.groupby(['business_id','topic','topic_name']).agg({'sentiment_val':'mean', \n",
    "                                                 'index':lambda x: x.nunique(),\n",
    "                                                 'counts': 'mean'                                                \n",
    "                                                }).reset_index()\n",
    "    aggs.columns = ['business_id','topic','topic_name','avg_sentiment', 'topic_count', 'sentence_count']\n",
    "    aggs['importance'] = aggs['topic_count']/aggs['sentence_count']\n",
    "    aggs = aggs.sort_values(by = ['business_id', 'importance'], ascending = False)\n",
    "    \n",
    "    return(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_aggs(name, df):\n",
    "    business_id = df['business_id'][df['name']==name][0]\n",
    "    aggs = get_aggs(business_id, df)\n",
    "    aggs['sentiment_score'] = [(100*X/3.0) for X in aggs['avg_sentiment']]\n",
    "    aggs = pd.Series(aggs.sentiment_score.values,index=aggs.topic_name).to_dict()\n",
    "    return(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_index</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94203.000000</td>\n",
       "      <td>9.420300e+04</td>\n",
       "      <td>94203.000000</td>\n",
       "      <td>94203.000000</td>\n",
       "      <td>94062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>293870.850865</td>\n",
       "      <td>2.711284e+06</td>\n",
       "      <td>6.066505</td>\n",
       "      <td>1.520228</td>\n",
       "      <td>0.480197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>199422.771554</td>\n",
       "      <td>1.806617e+06</td>\n",
       "      <td>7.441491</td>\n",
       "      <td>1.539223</td>\n",
       "      <td>0.220223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.910000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112426.500000</td>\n",
       "      <td>1.059243e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257604.000000</td>\n",
       "      <td>2.349673e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>464263.500000</td>\n",
       "      <td>4.271677e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>728216.000000</td>\n",
       "      <td>6.682752e+06</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  review_index  sentence_index         topic  \\\n",
       "count   94203.000000  9.420300e+04    94203.000000  94203.000000   \n",
       "mean   293870.850865  2.711284e+06        6.066505      1.520228   \n",
       "std    199422.771554  1.806617e+06        7.441491      1.539223   \n",
       "min        45.000000  4.910000e+02        0.000000      0.000000   \n",
       "25%    112426.500000  1.059243e+06        1.000000      0.000000   \n",
       "50%    257604.000000  2.349673e+06        4.000000      1.000000   \n",
       "75%    464263.500000  4.271677e+06        8.000000      3.000000   \n",
       "max    728216.000000  6.682752e+06       89.000000      4.000000   \n",
       "\n",
       "       sentiment_val  \n",
       "count   94062.000000  \n",
       "mean        0.480197  \n",
       "std         0.220223  \n",
       "min         0.000000  \n",
       "25%         0.250000  \n",
       "50%         0.500000  \n",
       "75%         0.750000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(df, cols):    \n",
    "    for col in cols:\n",
    "        max_value = df[col].max()\n",
    "        min_value = df[col].min()\n",
    "        df[col] = [(X - min_value) / (max_value - min_value) for X in df[col]]\n",
    "    return (df)\n",
    "df = normalize(df, ['sentiment_val'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza quality and style': 70.3499079189687,\n",
       " 'wait times': 62.12121212121212,\n",
       " 'variety/options': 74.58333333333333,\n",
       " 'service': 65.59139784946237,\n",
       " 'experience': 73.01587301587303}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = get_aspect_aggs(\"Pieology Pizzeria\", df)\n",
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': 'pizza quality and style',\n",
       "  'score': 70.3499079189687,\n",
       "  'sentences': ['The bread and tomato sauce was a novel idea and the bruschetta was also novel- on crispy pizza dough with fresh tomatoes',\n",
       "   '0/10: The bread and tomato sauce appetizer everyone raves about',\n",
       "   'Oh, and their bread and especially tomato dipping sauce were delicious']},\n",
       " {'aspect': 'wait times',\n",
       "  'score': 62.12121212121212,\n",
       "  'sentences': ['This was my first time going to Positano, it was a Sunday evening so the restaurant was not that busy',\n",
       "   'Have been here 7 times',\n",
       "   'We love this restaurant, the staff, and food are great']},\n",
       " {'aspect': 'variety/options',\n",
       "  'score': 74.58333333333333,\n",
       "  'sentences': ['Service is good',\n",
       "   '4/10: Service',\n",
       "   'Great food, service and value']},\n",
       " {'aspect': 'service',\n",
       "  'score': 65.59139784946237,\n",
       "  'sentences': ['Staff are super friendly',\n",
       "   'Staff are super friendly as well!',\n",
       "   'Very attentive staff']},\n",
       " {'aspect': 'experience',\n",
       "  'score': 73.01587301587303,\n",
       "  'sentences': [\"The last time I came, it was on a Saturday evening and the place was pretty busy which I don't understand why when there are better Italian restaurants in the area\",\n",
       "   'Decent quality Italian place in the Mt Pleasant / Eglinton area',\n",
       "   'And Il Sogno (in the area) has a far better spicy oil - but their food is overall even worse)']}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_id = 'zmfa8RNxqSuOJ9Nx-CMs_Q'\n",
    "results_all = []\n",
    "for k, v in aggs.items():\n",
    "    results_dict = {}\n",
    "    results_dict['aspect'] = k\n",
    "    results_dict['score'] = v\n",
    "    results_dict['sentences'] = get_rep_sentences_tname(business_id, k, 3)\n",
    "    results_all.append(results_dict)\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPvVGmT4AY1mloktV-2Dpw'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['business_id'][df['name']=='La Famiglia'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(name, df):\n",
    "    business_id = list(df['business_id'][df['name']==name])[0]\n",
    "    \n",
    "    aggs = get_aggs(business_id, df)\n",
    "    \n",
    "    summary = []\n",
    "    for t in list(aggs['topic'][aggs['business_id'] == business_id]):\n",
    "        summary.append(get_rep_sentences(business_id, t, 1)[0])\n",
    "    summary = '. '.join(summary)\n",
    "    return(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This pizza place makes my list of top five pizza places in Arizona very good pizza. Every time we order a take out pizza they give us a pick up time and it is NEVER ready on time, even when the restaurant is not busy at all. Great food and service. Food. I had a pizza and my husband the chicken Marsala'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(\"La Famiglia\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aspect overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    94062.000000\n",
       "mean         1.920786\n",
       "std          0.880893\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max          4.000000\n",
       "Name: sentiment_val, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_val'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_topics_lda(tokenized_text, num_topics):\n",
    "#     id2word = gensim.corpora.Dictionary(tokenized_text)\n",
    "#     corpus = [id2word.doc2bow(t) for t in tokenized_text]\n",
    "#     lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=num_topics, \n",
    "#                                            random_state=100,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=128,\n",
    "#                                            per_word_topics=True)\n",
    "#     return(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27032\n",
       "3    15616\n",
       "1    14263\n",
       "4    14048\n",
       "2    10900\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_subs = pd.DataFrame()\n",
    "# for t in df['topic']:\n",
    "#     print('topic:' t)\n",
    "    \n",
    "#     df_tmp = df['cleaned'][df['topic'] == t]\n",
    "    \n",
    "#     lda_model = get_topics_lda(df_tmp, 3)\n",
    "    \n",
    "#     lda_model.print_topics(num_words=20)\n",
    "    \n",
    "#     pd.to_pickle(lda_model, 'lda_subtopics_20k_'+str(t)+'.pkl')\n",
    "    \n",
    "#     get_document_topics = [lda_model.get_document_topics(item) for item in corpus]\n",
    "#     topics_dict = {}\n",
    "#     for i, doc in enumerate(get_document_topics):\n",
    "#         topics_dict[i] = max(doc,key=itemgetter(1))[0]\n",
    "#     main_topic = pd.DataFrame(list(topics_dict.items()), columns = ['index','sub_topic'+str(t)])\n",
    "    \n",
    "#     df_tmp = pd.concat([df_tmp.reset_index(), main_topic['sub_topic'+str(t)]], axis=1)\n",
    "    \n",
    "#     df_subs = pd.concat[df_subs, df_tmp]\n",
    "    \n",
    "#     del(df_tmp)\n",
    "\n",
    "#     print('completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
